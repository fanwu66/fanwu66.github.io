---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Fan Wu was born in Bozhou, Anhui, China in 2001. I'm currently pursuing the Ph.D. degree with the <a href="https://tc.seu.edu.cn/">School of Transportation</a>, <a href="https://www.seu.edu.cn/">Southeast University</a>, supervised by Prof. <a href="https://tc.seu.edu.cn/mgq/main.psp">Guoqiang Mao</a>. He received his M.S. degree from <a href="https://www.sspu.edu.cn/">Shanghai Polytechnic University</a> in 2022, supervised by Prof. <a href="https://imce.sspu.edu.cn/2024/0517/c5124a156030/page.psp">Shaojing Song</a> and <a href="https://jxxy.sspu.edu.cn/2025/1024/c5247a165417/page.htm">QingE Wu</a>. During the M.S. career, he has also worked as a research intern supervised by <a href="">Xinyu Zhang</a> from 2022.04 to 2024.06.

My research spans the tasks of 3D object detection, point cloud registration and human Identification, all aimed at achieving more accurate and robust perception, thereby reducing driving accidents.

<b>Fields:</b> Computer Vision, Autonomous, Vehicle-Infrastructure Cooperation, Large Vision-Language Model<br />

# üî• News


# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<b> BEVHeight: A Robust Framework for Vision-based Roadside 3D Object Detection </b>

<u><b>Lei Yang</b></u>, Kaicheng Yu, Tao Tang, Jun Li, Kun Yuan, Li Wang, Xinyu Zhang, Peng Chen.

<i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</i>

<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVHeight_A_Robust_Framework_for_Vision-Based_Roadside_3D_Object_Detection_CVPR_2023_paper.pdf">[Paper]</a> <a href="https://github.com/ADLab-AutoDrive/BEVHeight">[Code]</a> <a href="https://mp.weixin.qq.com/s/dLzZOEFfjBmLQ2iv041oxw">[Blog]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:2luZ8BuEgN8J:scholar.google.com/&output=citation&scisdr=Cm1glQeJEPG9riE6yO8:AGlGAw8AAAAAZIA80O9jVSfqal3uL4vf2p2Rm_c&scisig=AGlGAw8AAAAAZIA80DDZ1XCX-OXEz6g4SqICmj8&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTex]</a> 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<b> BEVHeight: A Robust Framework for Vision-based Roadside 3D Object Detection </b>

<u><b>Lei Yang</b></u>, Kaicheng Yu, Tao Tang, Jun Li, Kun Yuan, Li Wang, Xinyu Zhang, Peng Chen.

<i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</i>

<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVHeight_A_Robust_Framework_for_Vision-Based_Roadside_3D_Object_Detection_CVPR_2023_paper.pdf">[Paper]</a> <a href="https://github.com/ADLab-AutoDrive/BEVHeight">[Code]</a> <a href="https://mp.weixin.qq.com/s/dLzZOEFfjBmLQ2iv041oxw">[Blog]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:2luZ8BuEgN8J:scholar.google.com/&output=citation&scisdr=Cm1glQeJEPG9riE6yO8:AGlGAw8AAAAAZIA80O9jVSfqal3uL4vf2p2Rm_c&scisig=AGlGAw8AAAAAZIA80DDZ1XCX-OXEz6g4SqICmj8&scisf=4&ct=citation&cd=-1&hl=zh-CN">[BibTex]</a> 

</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.